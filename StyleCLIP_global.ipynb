{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleCLIP_global",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/others/blob/master/StyleCLIP_global.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFh0PtHAw5ax"
      },
      "source": [
        "# セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hlml6ebZ9xa"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "! git clone https://github.com/orpatashnik/StyleCLIP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaZbI-6maJin"
      },
      "source": [
        "# input dataset name \n",
        "dataset_name='ffhq' # input dataset name, currently, only support ffhq\n",
        "\n",
        "% cd StyleCLIP/global/\n",
        "\n",
        "# input prepare data \n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 'w'\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 's'\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 's_mean_std'\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from MapTS import GetFs,GetBoundary,GetDt\n",
        "from manipulate import Manipulator\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "M=Manipulator(dataset_name='ffhq')\n",
        "fs3=np.load('./npy/ffhq/fs3.npy')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQNEpDYfpup0"
      },
      "source": [
        "# GUIによる画像編集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Y31y0hpXbF"
      },
      "source": [
        "# 画像選択\n",
        "img_indexs=[1259]\n",
        "dlatent_tmp=[tmp[img_indexs] for tmp in M.dlatents]\n",
        "M.num_images=len(img_indexs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlekymCvpXlo"
      },
      "source": [
        "#テキスト入力\n",
        "neutral='face'\n",
        "target='smile face'\n",
        "classnames=[target,neutral]\n",
        "dt=GetDt(classnames,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjAf0M3ttM7x"
      },
      "source": [
        "#@markdown ###元画像表示\n",
        "beta = 0.1 \n",
        "alpha = 0 \n",
        "M.alpha=[alpha]\n",
        "boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "codes=M.MSCode(dlatent_tmp,boundary_tmp2)\n",
        "out=M.GenerateImg(codes)\n",
        "Image.fromarray(out[0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXgtSUvVpX64"
      },
      "source": [
        "#@markdown ###編集画像表示\n",
        "beta = 0.1 #@param {type:\"slider\", min:0.08, max:0.3, step:0.01}\n",
        "alpha = 2 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "M.alpha=[alpha]\n",
        "boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "codes=M.MSCode(dlatent_tmp,boundary_tmp2)\n",
        "out=M.GenerateImg(codes)\n",
        "Image.fromarray(out[0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKF-2zrFqILy"
      },
      "source": [
        "# 画像編集ビデオ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fhnU7Lnq2Tj"
      },
      "source": [
        "# 画像の選択\n",
        "img_indexs=[1276]\n",
        "dlatent_tmp=[tmp[img_indexs] for tmp in M.dlatents]\n",
        "M.num_images=len(img_indexs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxUlRCeOqn-J"
      },
      "source": [
        "# テキスト入力\n",
        "neutral='face with hair'\n",
        "target='Curly Hair'\n",
        "classnames=[target,neutral]\n",
        "dt=GetDt(classnames,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07NGF7LFqoHD"
      },
      "source": [
        "# 段階的な編集画像の保存\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('pic'):\n",
        "     shutil.rmtree('pic')\n",
        "os.makedirs('pic', exist_ok=True)\n",
        "cnt = 0\n",
        "for i in range(0,20,1):\n",
        "     beta = 0.1 \n",
        "     alpha = i/10 \n",
        "     M.alpha=[alpha]\n",
        "     boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "     codes=M.MSCode(dlatent_tmp,boundary_tmp2)\n",
        "     out=M.GenerateImg(codes)\n",
        "     pic = Image.fromarray(out[0,0])\n",
        "     pic.save('./pic/'+str(cnt).zfill(6)+'.png')     \n",
        "     cnt +=1\n",
        "\n",
        "for i in range(20,0,-1):\n",
        "     beta = 0.1 \n",
        "     alpha = i/10 \n",
        "     M.alpha=[alpha]\n",
        "     boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "     codes=M.MSCode(dlatent_tmp,boundary_tmp2)\n",
        "     out=M.GenerateImg(codes)\n",
        "     pic = Image.fromarray(out[0,0])\n",
        "     pic.save('./pic/'+str(cnt).zfill(6)+'.png')     \n",
        "     cnt +=1     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKYEVW4PJXWk"
      },
      "source": [
        "# 段階的な編集画像を動画に変換\n",
        "! ffmpeg -r 10 -i pic/%6d.png\\\n",
        "              -vcodec libx264 -pix_fmt yuv420p output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9caPRkYaFCiJ"
      },
      "source": [
        "# Play the generated video\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def video(path):\n",
        "  mp4 = open(path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  return HTML('<video width=500 controls loop> <source src=\"%s\" type=\"video/mp4\"></video>' % data_url)\n",
        "\n",
        "video('output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}