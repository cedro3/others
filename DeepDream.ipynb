{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cedro3/others/blob/master/DeepDream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4RBFfIWNbG0"
   },
   "source": [
    "## セットアップ\n",
    "ライブラリーの読み込み、クラスと関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRScWg_VNqvj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Input image\n",
    "def input(image, max_dim=None):\n",
    "  img = PIL.Image.open(image)\n",
    "  if max_dim:\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "  return np.array(img)\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "  img = 255*(img + 1.0)/2.0\n",
    "  return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "  display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "# Calc loss\n",
    "def calc_loss(img, model):\n",
    "  img_batch = tf.expand_dims(img, axis=0)\n",
    "  layer_activations = model(img_batch)\n",
    "  if len(layer_activations) == 1:\n",
    "    layer_activations = [layer_activations]\n",
    "\n",
    "  losses = []\n",
    "  for act in layer_activations:\n",
    "    loss = tf.math.reduce_mean(act)\n",
    "    losses.append(loss)\n",
    "\n",
    "  return  tf.reduce_sum(losses)\n",
    "\n",
    "# Class DeepDream\n",
    "class DeepDream(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "  )\n",
    "  def __call__(self, img, steps, step_size):\n",
    "      loss = tf.constant(0.0)\n",
    "      for n in tf.range(steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "          tape.watch(img)\n",
    "          loss = calc_loss(img, self.model)\n",
    "\n",
    "        gradients = tape.gradient(loss, img)\n",
    "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "        \n",
    "        img = img + gradients*step_size\n",
    "        img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      return loss, img\n",
    "\n",
    "# run_simple\n",
    "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "  img = tf.convert_to_tensor(img)\n",
    "  step_size = tf.convert_to_tensor(step_size)\n",
    "  steps_remaining = steps\n",
    "  step = 0\n",
    "  while steps_remaining:\n",
    "    if steps_remaining>100:\n",
    "      run_steps = tf.constant(100)\n",
    "    else:\n",
    "      run_steps = tf.constant(steps_remaining)\n",
    "    steps_remaining -= run_steps\n",
    "    step += run_steps\n",
    "\n",
    "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "  result = deprocess(img)  \n",
    "  return result\n",
    "\n",
    "# run_octave\n",
    "def octave(original_img):\n",
    "   OCTAVE_SCALE = 1.30\n",
    "   img = tf.constant(np.array(original_img))\n",
    "   base_shape = tf.shape(img)[:-1]\n",
    "   float_base_shape = tf.cast(base_shape, tf.float32)\n",
    "\n",
    "   for n in range(-2, 3):\n",
    "        new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
    "        img = tf.image.resize(img, new_shape).numpy()\n",
    "        img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
    "        img = tf.image.resize(img, base_shape)       \n",
    "        img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "   return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0WWczheOwDf"
   },
   "source": [
    "# サンプルデータのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VsZijq0M7kW"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cedro3/Sample.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2oFtzu-ETlo"
   },
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkHkYEqbDC7E"
   },
   "outputs": [],
   "source": [
    "# ベースモデル InceptionV3 のダウンロード\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "# Maximize the activations of these layers\n",
    "names = ['mixed3', 'mixed5']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "# make model\n",
    "deepdream = DeepDream(dream_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-VFUjetXFi-"
   },
   "source": [
    "# octave バージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T39U0ZWSNDbi"
   },
   "outputs": [],
   "source": [
    "# 静止画をDeepDreamに変換(octave)\n",
    "original_img = input('./Sample/animal_pic/dog.png')\n",
    "img = octave(original_img)\n",
    "show(original_img)\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfT1RmgEUH9d"
   },
   "outputs": [],
   "source": [
    "# ビデオを静止画に変換\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# 既にimagesフォルダーがあれば削除\n",
    "if os.path.isdir('images'):\n",
    "    shutil.rmtree('images')\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    " \n",
    "def video_2_images(video_file= './Sample/video/elephant.mp4',   # ビデオの指定\n",
    "                   image_dir='./images/', \n",
    "                   image_file='%s.png'):\n",
    " \n",
    "    # Initial setting\n",
    "    i = 0\n",
    "    interval = 6\n",
    "    length = 300  # 最大フレーム数\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    while(cap.isOpened()):\n",
    "        flag, frame = cap.read()  \n",
    "        if flag == False:  \n",
    "                break\n",
    "        if i == length*interval:\n",
    "                break\n",
    "        if i % interval == 0:    \n",
    "           cv2.imwrite(image_dir+image_file % str(int(i/interval)).zfill(6), frame)\n",
    "        i += 1 \n",
    "    cap.release()  \n",
    " \n",
    "def main():\n",
    "    video_2_images()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRTrM2SZyoSh"
   },
   "outputs": [],
   "source": [
    "# 静止画をDeepDream画像へ変換(octave)\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "files=[]\n",
    "for name in sorted(glob.glob('./images/*.png')):\n",
    "     files.append(name)\n",
    "\n",
    "for file in tqdm(files):\n",
    "     original_img=input(file)\n",
    "     dream_img = octave(original_img)\n",
    "     PIL.Image.fromarray(np.array(dream_img)).save(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8jrxvrgcJ2Q"
   },
   "outputs": [],
   "source": [
    "# DeepDream画像をmp4に変換\n",
    "!ffmpeg -r 6 -i images/%06d.png -vcodec libx264 -pix_fmt yuv420p output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVLTmQL7cJ_8"
   },
   "outputs": [],
   "source": [
    "# mp4動画の再生\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open('./output.mp4', 'rb').read()\n",
    "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"80%\" height=\"80%\" controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ5t215rUPlS"
   },
   "source": [
    "# simple バージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xWdtQ_IR7CR"
   },
   "outputs": [],
   "source": [
    "# 静止画をDeepDreamに変換(simple)\n",
    "original_img = input('./Sample/animal_pic/dog.png')\n",
    "img = run_deep_dream_simple(original_img)\n",
    "show(original_img)\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG_RI44NTLhE"
   },
   "outputs": [],
   "source": [
    "# ビデオを静止画に変換\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# 既にimagesフォルダーがあれば削除\n",
    "if os.path.isdir('images'):\n",
    "    shutil.rmtree('images')\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    " \n",
    "def video_2_images(video_file= './Sample/video/elephant.mp4',   # ビデオの指定\n",
    "                   image_dir='./images/', \n",
    "                   image_file='%s.png'):\n",
    " \n",
    "    # Initial setting\n",
    "    i = 0\n",
    "    interval = 6\n",
    "    length = 300  # 最大フレーム数\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    while(cap.isOpened()):\n",
    "        flag, frame = cap.read()  \n",
    "        if flag == False:  \n",
    "                break\n",
    "        if i == length*interval:\n",
    "                break\n",
    "        if i % interval == 0:    \n",
    "           cv2.imwrite(image_dir+image_file % str(int(i/interval)).zfill(6), frame)\n",
    "        i += 1 \n",
    "    cap.release()  \n",
    " \n",
    "def main():\n",
    "    video_2_images()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcyGJkVFtDsK"
   },
   "outputs": [],
   "source": [
    "# 静止画をDeepDream画像へ変換(simple)\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "files=[]\n",
    "for name in sorted(glob.glob('./images/*.png')):\n",
    "     files.append(name)\n",
    "\n",
    "for file in tqdm(files):\n",
    "     original_img=input(file)\n",
    "     dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)\n",
    "     PIL.Image.fromarray(np.array(dream_img)).save(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "macVyBdETipx"
   },
   "outputs": [],
   "source": [
    "# DeepDream画像をmp4に変換\n",
    "!ffmpeg -r 6 -i images/%06d.png -vcodec libx264 -pix_fmt yuv420p output2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8jIlhi9Tt-H"
   },
   "outputs": [],
   "source": [
    "# mp4動画の再生\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open('./output2.mp4', 'rb').read()\n",
    "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"80%\" height=\"80%\" controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DeepDream",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
