{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DALL_E",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/others/blob/master/DALL_E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nD1n0xEBcko"
      },
      "source": [
        "# セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N65H8lL1cR1V"
      },
      "source": [
        "# GPUスペック確認\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4iTie2EKrbb"
      },
      "source": [
        "# Pytorchバージョン変更\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "\n",
        "# Pytorch画像処理ライブラリー・インストール\n",
        "! pip install kornia\n",
        "\n",
        "# CLIP関連コードのコピー\n",
        "! git clone https://github.com/openai/CLIP.git\n",
        "%cd /content/CLIP/\n",
        "\n",
        "# CLIPのモデル化\n",
        "! pip install ftfy regex\n",
        "import clip\n",
        "model, preprocess = clip.load('ViT-B/32', jit=True)  \n",
        "model = model.eval()  \n",
        "\n",
        "# DALL-Eのモデル化\n",
        "! pip install DALL-E\n",
        "from dall_e import map_pixels, unmap_pixels, load_model\n",
        "dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", 'cuda')  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAcixx9Z3XYH"
      },
      "source": [
        "# ライブラリー・インポート＆関数定義\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piJOg9MY7khd"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "import kornia\n",
        "import PIL\n",
        "import os, io, sys\n",
        "import random\n",
        "import imageio\n",
        "from IPython import display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from google.colab import output\n",
        "import requests\n",
        "\n",
        "# 初期設定\n",
        "im_shape = [512, 512, 3]\n",
        "sideX, sideY, channels = im_shape\n",
        "target_image_size = sideX\n",
        "tau_value = 2.\n",
        "\n",
        "# 画像表示・保存\n",
        "def displ(img):\n",
        "  img = np.array(img)[:,:,:]\n",
        "  img = np.transpose(img, (1, 2, 0))\n",
        "  imageio.imwrite('output.png', np.array(img))\n",
        "  return display.Image('output.png')\n",
        "\n",
        "# 画像のランダム切り出し\n",
        "def augment(out, cutn=16):\n",
        "  p_s = []\n",
        "  for ch in range(cutn):\n",
        "    sizey = int(torch.zeros(1,).uniform_(.5, .99)*sideY)\n",
        "    sizex = int(torch.zeros(1,).uniform_(.5, .99)*sideX)\n",
        "    offsetx = torch.randint(0, sideX - sizex, ())\n",
        "    offsety = torch.randint(0, sideY - sizey, ())\n",
        "    apper = out[:, :, offsetx:offsetx + sizex, offsety:offsety + sizey]\n",
        "    apper = apper + .1*torch.rand(1,1,1,1).cuda()*torch.randn_like(apper, requires_grad=True)\n",
        "    apper = torch.nn.functional.interpolate(apper, (224,224), mode='bilinear')\n",
        "    p_s.append(apper)\n",
        "  into = augs(torch.cat(p_s, 0))\n",
        "  return into\n",
        "\n",
        "# 正規化と回転設定\n",
        "nom = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "augs = kornia.augmentation.RandomRotation(30).cuda()\n",
        "\n",
        "# パラメータの設定\n",
        "class Pars(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Pars, self).__init__()\n",
        "        hots = torch.nn.functional.one_hot((torch.arange(0, 8192).to(torch.int64)), num_classes=8192)\n",
        "        rng = torch.zeros(1, 64*64, 8192).uniform_()\n",
        "        for i in range(64*64):\n",
        "            rng[0,i] = hots[[np.random.randint(8191)]]\n",
        "        rng = rng.permute(0, 2, 1)\n",
        "        self.normu = torch.nn.Parameter(rng.cuda().view(1, 8192, 64*64))\n",
        "        \n",
        "    def forward(self):      \n",
        "      normu = torch.nn.functional.gumbel_softmax(self.normu.reshape(1,64*64,8192), dim=1, tau=tau_value).view(1, 8192, 64, 64)\n",
        "      return normu \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaocGDQXz3Zx"
      },
      "source": [
        "# テキストから画像の生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGWtvVB-arNH"
      },
      "source": [
        "**テキストから特徴ベクトルを抽出**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGBTOiJqWgZ3"
      },
      "source": [
        "# テキスト入力\n",
        "text_input = 'an armchair in the shape of an avocado'\n",
        "\n",
        "# テキストを特徴ベクトルに変換\n",
        "token = clip.tokenize(text_input)  \n",
        "text_v = model.encode_text(token.cuda()).detach().clone() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WztSrRF23Rqg"
      },
      "source": [
        "**学習**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYNUzzovPEW"
      },
      "source": [
        "# パラメータリセット\n",
        "latent = Pars().cuda()  \n",
        "param = [latent.normu]  \n",
        "optimizer = torch.optim.Adam([{'params': param, 'lr': .01}]) \n",
        "\n",
        "# images フォルダーリセット\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('images'):\n",
        "   shutil.rmtree('images')\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "# 学習ループ\n",
        "for iteration in range(1001):\n",
        "\n",
        "  # --- 順伝播 ---\n",
        "  # パラメータから画像を生成\n",
        "  out = unmap_pixels(torch.sigmoid(dec(latent())[:, :3].float()))\n",
        "  # 画像をランダム切り出し・回転  \n",
        "  into = augment(out)\n",
        "  # 画像を正規化\n",
        "  into = nom((into))\n",
        "  # 画像から特徴ベクトルを取得\n",
        "  image_v = model.encode_image(into)\n",
        "  # テキストと画像の特徴ベクトルのCOS類似度を計算 \n",
        "  loss = -torch.cosine_similarity(text_v, image_v).mean()  \n",
        "\n",
        "  # 逆伝播\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step() \n",
        "\n",
        "  # 学習率の調整\n",
        "  for g in optimizer.param_groups:\n",
        "    g['lr'] = g['lr']*1.005\n",
        "    g['lr'] = min(g['lr'], .12)\n",
        "\n",
        "  # ログ表示      \n",
        "  if iteration % 50 == 0:\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # 生成画像の表示・保存\n",
        "      out = unmap_pixels(torch.sigmoid(dec(latent())[:, :3]).float())  \n",
        "      displ(out.cpu()[0])  \n",
        "      shutil.copy('output.png', './images/%s.png'%str(int(iteration/50)).zfill(6))\n",
        "\n",
        "      # データ表示\n",
        "      print('iter = ',iteration)\n",
        "      for g in optimizer.param_groups:\n",
        "        print('lr = ', g['lr'])\n",
        "      print('tau_value = ', tau_value)\n",
        "      print('loss = ',loss.item())\n",
        "      print('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zclMtW3CaSNX"
      },
      "source": [
        "# 学習過程の動画作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zxCTHkJbBD9"
      },
      "source": [
        "**mp4動画の作成**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcIHq0zsY8OC"
      },
      "source": [
        "# images フォルダーの最後の画像を5枚コピー\n",
        "import shutil\n",
        "for i in range(21,26,1):\n",
        "    shutil.copy('output.png', './images/%s.png'%str(int(i)).zfill(6))\n",
        "\n",
        "# ouput.mp4を一旦削除\n",
        "import os \n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "# images フォルダーの画像から動画を生成\n",
        "! ffmpeg -r 5 -i images/%06d.png -vcodec libx264 -pix_fmt yuv420p output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzoB1G26bFwX"
      },
      "source": [
        "**mp4動画の再生**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1rs5DnwZvuh"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}