{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtLine_make_gif",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/others/blob/master/ArtLine_make_gif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOhPqC6fysD4"
      },
      "source": [
        "# **ArtLine_make_gif**\n",
        "**Create** **Amazing** **Line** **Art**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzHW4dq4ys7_"
      },
      "source": [
        "# copy github\n",
        "!git clone https://github.com/vijishmadhavan/ArtLine.git ArtLine\n",
        "%cd ArtLine/\n",
        "\n",
        "# get libralies\n",
        "!pip install -r colab_requirements.txt\n",
        "!pip install -q youtube-dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cjGDScH86iU"
      },
      "source": [
        "# **Runtime**\n",
        "\n",
        "* Hardware Accelerator = GPU              \n",
        "You have to click twice\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnC6OObV3sNk"
      },
      "source": [
        "import fastai\n",
        "from fastai.vision import *\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, image, torch\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, image, torch\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class FeatureLoss(nn.Module):\n",
        "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
        "        super().__init__()\n",
        "        self.m_feat = m_feat\n",
        "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "        self.wgts = layer_wgts\n",
        "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "    def make_features(self, x, clone=False):\n",
        "        self.m_feat(x)\n",
        "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "    \n",
        "    def forward(self, input, target):\n",
        "        out_feat = self.make_features(target, clone=True)\n",
        "        in_feat = self.make_features(input)\n",
        "        self.feat_losses = [base_loss(input,target)]\n",
        "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "        return sum(self.feat_losses)\n",
        "    \n",
        "    def __del__(self): self.hooks.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmLIGUuu3vp5"
      },
      "source": [
        "MODEL_URL = \"https://www.dropbox.com/s/p9lynpwygjmeed2/ArtLine_500.pkl?dl=1 \"\n",
        "urllib.request.urlretrieve(MODEL_URL, \"ArtLine_500.pkl\")\n",
        "path = Path(\".\")\n",
        "learn=load_learner(path, 'ArtLine_500.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teAfEed9GOdX"
      },
      "source": [
        "# check YouTubeVideo\n",
        "from IPython.display import YouTubeVideo\n",
        "YOUTUBE_ID ='m0u0uAhoxq4'\n",
        "YouTubeVideo(YOUTUBE_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl9MwHi89M4C"
      },
      "source": [
        "# download YouTubeVideo\n",
        "!rm -rf youtube.mp4\n",
        "!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoVhz1KEiWcV"
      },
      "source": [
        "# edit YouTubeVideo\n",
        "import os\n",
        "os.makedirs('video', exist_ok=True)\n",
        "!ffmpeg -i youtube.mp4 -filter:v 'crop=300:300:170:0' -ss 00:00:01 -t 00:00:02 -async 1 ./video/takikuri.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LUgHbTyMlJt"
      },
      "source": [
        "# video2frames\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        " \n",
        "def video_2_frames(video_file='./video/takikuri.mp4', \n",
        "                   image_dir='./images/', \n",
        "                   image_file='img_%s.png'):\n",
        " \n",
        "    # Initial setting\n",
        "    i = 0\n",
        "    interval = 3\n",
        "    length = 30\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    while(cap.isOpened()):\n",
        "        flag, frame = cap.read()  \n",
        "        if flag == False:  \n",
        "                break\n",
        "        if i == length*interval:\n",
        "                break\n",
        "        if i % interval == 0:    \n",
        "           cv2.imwrite(image_dir+image_file % str(i).zfill(6), frame)\n",
        "           print('Save', image_dir+image_file % str(i).zfill(6))\n",
        "        i += 1 \n",
        "    cap.release()  \n",
        " \n",
        "def main():\n",
        "    video_2_frames()\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main()  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeSLtsxqHqEV"
      },
      "source": [
        "# frames2ArtLines\n",
        "import os\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "os.makedirs('out', exist_ok=True)\n",
        "\n",
        "input_path = './images' \n",
        "output_path = './out'\n",
        "files = os.listdir(input_path)\n",
        "files.sort()\n",
        "\n",
        "temp =[add_metrics]\n",
        "\n",
        "for file in files:\n",
        "  print(file)\n",
        "  if file == '.ipynb_checkpoints':\n",
        "     continue\n",
        "  img = PIL.Image.open(input_path+'/'+file).convert(\"RGB\")\n",
        "  img_t = T.ToTensor()(img)\n",
        "  img_fast = Image(img_t)\n",
        "  p,img_hr,b = learn.predict(img_fast)\n",
        "  vutils.save_image(img_hr,output_path+'/'+file)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbmPUrXcQNRm"
      },
      "source": [
        "# ArtLines2GIF\n",
        "from PIL import Image\n",
        "import glob\n",
        " \n",
        "files = sorted(glob.glob('./out/*.png'))\n",
        "images = list(map(lambda file: Image.open(file), files))\n",
        "images[0].save('./takikuri.gif', save_all=True, \n",
        "               append_images=images[1:], \n",
        "               duration=100, loop=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3MDH6Q1pzV"
      },
      "source": [
        "# display GIF\n",
        "from IPython.display import Image\n",
        "Image('./takikuri.gif', format='png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}